{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786d125f-3afd-4c52-99ee-02e86a7bec99",
   "metadata": {},
   "source": [
    "# Shelby Howard CISB63 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5631cd74-d9d9-4852-a7dc-427435b51d72",
   "metadata": {},
   "source": [
    "## My Trivia Chatbot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d2c29-441e-4573-83e8-33da5b704800",
   "metadata": {},
   "source": [
    "For my final project, I developed an automated trivia chatbot that prompts users with random questions and tracks their scores. The data was sourced from the Washington University website and organized into questions and answers. I implemented functions to clean the data, check user responses for correctness, and run the chatbot. The chatbot was created by integrating these functions into a loop that asks questions, evaluates answers, and provides feedback to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f39f27-5424-4fd2-bcdc-8c07897fb514",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09149bd-5c5a-4a0c-8771-bde0aae34809",
   "metadata": {},
   "source": [
    "Data: https://nlp.cs.washington.edu/triviaqa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c61168-616e-4c72-a7db-87d6c6d3a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tarfile so I can download the data\n",
    "import tarfile\n",
    "\n",
    "#My path\n",
    "path = \"/Users/shelbyhoward/Downloads/Triva Final/data.tar.gz\"\n",
    "\n",
    "extract_path = \"/Users/shelbyhoward/Downloads/Triva Final/extracted_data\"\n",
    "#Extract tar.gz file\n",
    "with tarfile.open(path, 'r:gz') as tar:\n",
    "    tar.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39301f7c-2a46-4cdc-9b5d-e46270b695f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries and load dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import nltk\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112b370f-5dfe-4c0d-a4e9-fd8346878270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shelbyhoward/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shelbyhoward/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/shelbyhoward/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/shelbyhoward/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/shelbyhoward/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the NLTK packages\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"maxent_ne_chunker\")\n",
    "nltk.download(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e02c54-0fa7-432b-badd-14c861edb3e6",
   "metadata": {},
   "source": [
    "## Create the Dataframe and Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e915bb2a-bdde-4676-bf59-2f2b86408b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pandas download the data into a dataframe from thee xtracted path\n",
    "df = pd.read_json('extracted_data/triviaqa-unfiltered/unfiltered-web-train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a594e4e-6cef-4fcc-8685-b13c8689aa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Split</th>\n",
       "      <th>VerifiedEval</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Answer': {'Aliases': ['Presidency of Harry S...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'Answer': {'Aliases': ['(Harry) Sinclair Lewi...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'Answer': {'Aliases': ['Park Grove (1895)', '...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'Answer': {'Aliases': ['Beer Cans'], 'Normali...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'Answer': {'Aliases': ['30's', '30‚Äôs', '30s',...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data          Domain  Split  \\\n",
       "0  {'Answer': {'Aliases': ['Presidency of Harry S...  unfiltered-web  train   \n",
       "1  {'Answer': {'Aliases': ['(Harry) Sinclair Lewi...  unfiltered-web  train   \n",
       "2  {'Answer': {'Aliases': ['Park Grove (1895)', '...  unfiltered-web  train   \n",
       "3  {'Answer': {'Aliases': ['Beer Cans'], 'Normali...  unfiltered-web  train   \n",
       "4  {'Answer': {'Aliases': ['30's', '30‚Äôs', '30s',...  unfiltered-web  train   \n",
       "\n",
       "   VerifiedEval  Version  \n",
       "0         False        1  \n",
       "1         False        1  \n",
       "2         False        1  \n",
       "3         False        1  \n",
       "4         False        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the unfiltered head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced3c6bf-2127-4360-bbbe-89081c073f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Split</th>\n",
       "      <th>VerifiedEval</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87617</th>\n",
       "      <td>{'Answer': {'Aliases': ['Rock Lobster by the B...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87618</th>\n",
       "      <td>{'Answer': {'Aliases': ['Wascally wabbit', 'Bu...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87619</th>\n",
       "      <td>{'Answer': {'Aliases': ['All the kings horses ...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87620</th>\n",
       "      <td>{'Answer': {'Aliases': ['Okypete', 'Snatchers'...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87621</th>\n",
       "      <td>{'Answer': {'Aliases': ['Butterfingers Snacker...</td>\n",
       "      <td>unfiltered-web</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Data          Domain  \\\n",
       "87617  {'Answer': {'Aliases': ['Rock Lobster by the B...  unfiltered-web   \n",
       "87618  {'Answer': {'Aliases': ['Wascally wabbit', 'Bu...  unfiltered-web   \n",
       "87619  {'Answer': {'Aliases': ['All the kings horses ...  unfiltered-web   \n",
       "87620  {'Answer': {'Aliases': ['Okypete', 'Snatchers'...  unfiltered-web   \n",
       "87621  {'Answer': {'Aliases': ['Butterfingers Snacker...  unfiltered-web   \n",
       "\n",
       "       Split  VerifiedEval  Version  \n",
       "87617  train         False        1  \n",
       "87618  train         False        1  \n",
       "87619  train         False        1  \n",
       "87620  train         False        1  \n",
       "87621  train         False        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the unfiltered tail\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4516d14-426c-46a6-8214-b7c9b0cf422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87622 entries, 0 to 87621\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Data          87622 non-null  object\n",
      " 1   Domain        87622 non-null  object\n",
      " 2   Split         87622 non-null  object\n",
      " 3   VerifiedEval  87622 non-null  bool  \n",
      " 4   Version       87622 non-null  int64 \n",
      "dtypes: bool(1), int64(1), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#Print the info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e578f1-8130-492b-87e0-13a3b48f000a",
   "metadata": {},
   "source": [
    "## Clean up the Data\n",
    "\n",
    "In the follwoing section I focused on seprating my data into two sections, questions and answers. This made the data easy to work with and easy to spot any mistakes incase my chatbot was having any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b80a23c-10fa-4bc8-86d5-0c26648526a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a function I need to extract all of the questions and answers from the data\n",
    "def extract_question_answer(entry):\n",
    "    try:\n",
    "        #using entry.get, get the questions\n",
    "        question = entry.get('Question', 'Unknown Question')\n",
    "        #using entry.get, get the answers\n",
    "        answer = entry.get('Answer', {}).get('NormalizedValue', 'Unknown Answer')\n",
    "        return {\"Question\": question, \"Answer\": answer}\n",
    "    except AttributeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5240cefb-76cd-4cc6-9fa2-92c1cb5e2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new data, apply the function, and drop all empty questions and answers.\n",
    "trivia_data = df['Data'].apply(extract_question_answer).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53bf948b-b1ee-4aed-8224-36c7e72b7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move the data into a dataframe\n",
    "trivia_df = pd.DataFrame(trivia_data.tolist())\n",
    "#New path\n",
    "cleaned_data_path = \"cleaned_trivia_data.json\"\n",
    "\n",
    "trivia_df.to_json(cleaned_data_path, orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661f6db-0b37-476b-ae9a-d1ebca6a8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imported need packages\n",
    "import json\n",
    "\n",
    "#Load the cleaned JSON data\n",
    "cleaned_data_path = \"cleaned_trivia_data.json\"\n",
    "\n",
    "#Open the file\n",
    "try:\n",
    "    with open(cleaned_data_path, 'r') as file:\n",
    "        cleaned_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439f7871-3a85-473a-b4c8-32dd23b9f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Cleaned Data:\n",
      "Question: Who was President when the first Peanuts cartoon was published?\n",
      "Answer: harry truman\n",
      "------------------------------\n",
      "Question: Which American-born Sinclair won the Nobel Prize for Literature in 1930?\n",
      "Answer: sinclair lewis\n",
      "------------------------------\n",
      "Question: Where in England was Dame Judi Dench born?\n",
      "Answer: york\n",
      "------------------------------\n",
      "Question: William Christensen of Madison, New Jersey, has claimed to have the world's biggest collection of what?\n",
      "Answer: beer cans\n",
      "------------------------------\n",
      "Question: In which decade did Billboard magazine first publish and American hit chart?\n",
      "Answer: 30s\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Check our work by printing out the first few questions\n",
    "    for entry in cleaned_data[:5]:  \n",
    "        print(f\"Question: {entry['Question']}\")\n",
    "        print(f\"Answer: {entry['Answer']}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Try again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9955e9-50c4-4ebe-9d32-11813bfc1731",
   "metadata": {},
   "source": [
    "## Using NLP to ensure correct matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea820899-40bc-4f51-ba83-672716b15d13",
   "metadata": {},
   "source": [
    "I chose to use natural language processing (NLP) to make the chatbot more user-friendly by allowing flexible answer matching, accounting for variations in user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "641a770e-781e-4134-8b6a-e21d520a925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMport need packages for NLP and cleaning up the data futher\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d992a534-e16c-446f-932b-9ff63908c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function for tokenizing, lowercasing, and removing stopwords\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    #Returns a list of cleaned tokens\n",
    "    filtered_tokens = [token for token in tokens if token.isalnum() and token not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "132f03f2-5c65-4a11-9748-433fa9ae1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to compare user answers with correct answers using NLP techniques.\n",
    "def is_answer_correct(user_answer, correct_answer):\n",
    "    user_tokens = preprocess_text(user_answer)\n",
    "    correct_tokens = preprocess_text(correct_answer)\n",
    "    #Returns True if they match, it will come back as false\n",
    "    return set(user_tokens) == set(correct_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbe6c8-0b04-43c8-92fb-219026a48327",
   "metadata": {},
   "source": [
    "## Chatbot Function\n",
    "\n",
    "Creating dedicated functions before hand for data cleaning and response validation ensured modularity and made the chatbot easier to maintain and expand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3db2f76-dacc-4cbd-8c37-a3202aa72929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to run my trivia chatbot\n",
    "def trivia_chatbot(json_path):\n",
    "    #Open the file\n",
    "    with open(json_path, 'r') as file:\n",
    "        questions = json.load(file)\n",
    "\n",
    "    #To keep count, start the counters at 0\n",
    "    correct_count = 0  # Track correct answers\n",
    "    asked_questions_count = 0  # Track how many questions were asked\n",
    "\n",
    "    #Start with an opening statement\n",
    "    print(\"Welcome to your personal Trivia Chatbot! Type 'quit' when you are ready to exit.\\n\")\n",
    "\n",
    "    #While loop for questions\n",
    "    while True:\n",
    "        #Randomly select a trivia question\n",
    "        question = random.choice(questions)\n",
    "        #Ask the use the question\n",
    "        print(\"Question:\", question['Question'])\n",
    "        \n",
    "        #Get the user's answer\n",
    "        user_answer = input(\"Your Answer: \").strip()\n",
    "        #If user inserts quit, program will exit\n",
    "        if user_answer.lower() == \"quit\":\n",
    "            print(f\"Thanks for playing! You got {correct_count}/{asked_questions_count} correct!\")\n",
    "            break\n",
    "        \n",
    "        #Check if the answer is correct\n",
    "        correct_answer = question['Answer']\n",
    "        #If it matches, print correct\n",
    "        if is_answer_correct(user_answer, correct_answer):\n",
    "            print(\"Correct! Let do another....\\n\")\n",
    "            #Increase correct count\n",
    "            correct_count += 1 \n",
    "        else:\n",
    "            print(f\"Wrong! The correct answer was: {correct_answer}\\n\")\n",
    "        #Increment the number of questions asked\n",
    "        asked_questions_count += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eb0a12-1869-4a49-96f7-a0710fcdd52b",
   "metadata": {},
   "source": [
    "# Final Triva Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1568a77-f95c-41c2-b18e-a9fbf0cf38d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Trivia Chatbot! Type 'exit' to quit.\n",
      "\n",
      "Question: What is Frigophobia the fear of\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  fridges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: being cold\n",
      "\n",
      "Question: Give a year in the life of prison reformer Elizabeth Fry.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: 1780 1845\n",
      "\n",
      "Question: What is the common name for the bird Passer domesticus?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: house sparrow\n",
      "\n",
      "Question: In what is now Iran in 1951 to 1954, what led to the Shah fleeing the country, the Prime Minister trying to dissolve parliament, crude oil being imported from Kuwait, and a breakdown of diplomatic relations with Britain and the USA?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: persian oil dispute\n",
      "\n",
      "Question: The principal Deputy Speaker of the House of Commons has the official title Chairman of Ways and Means. Who is the current holder of the post, the MP for Chorley?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: lindsay hoyle\n",
      "\n",
      "Question: At which racecourse did Lester Piggott ride both his first and last winners?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  Kuntucky Derby \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: haydock park\n",
      "\n",
      "Question: What type of volcanic stone is commonly used during pedicures?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  Lava Rock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: pumice\n",
      "\n",
      "Question: The film 'You've Got Mail' reunited the male and female leads from which hit 1993 movie?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: sleepless in seattle tom hanks meg ryan\n",
      "\n",
      "Question: The President of which African country resigned in February 2011 after widespread protests calling for his departure?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: egypt\n",
      "\n",
      "Question: Name the Danish maritime explorer who served with the Russian fleet and gave his name to a Strait, a Sea, an Island, a Glacier and Land Bridge?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: vitus bering\n",
      "\n",
      "Question: Die Dreigroschenoper (The Threepenny Opera) by Kurt Weill was based on which work?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: beggars opera\n",
      "\n",
      "Question: What is the name given to a class of coal that contains a high percentage of fired carbon and burns smokelessly with intense heat?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  High\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: anthracite\n",
      "\n",
      "Question: \"Which airline used to promote itself as \"\"The world's favourite airline\"\"?\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  American Airline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: british airways\n",
      "\n",
      "Question: Which now defunct car manufacturer produced models called Vedette, Aronde and Ariane? SIMCA\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  Toyota\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: 2 with which sporting event is dane tom kristensen particularly associated having won it eight times le mans\n",
      "\n",
      "Question: Living History' is the memoir of which contemporary US politician?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: hillary clinton\n",
      "\n",
      "Question: Sir Humphry Repton achieved fame in the 18th century in which sphere of activity?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: landscape gardening\n",
      "\n",
      "Question: \"What model/rapper had a #1 hit in 2014 with her song \"\"Fancy\"\"?\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  Iggy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: iggy azalea\n",
      "\n",
      "Question: Who is the former Chief Constable of Merseyside, now Commissioner of the Metropolitan Police?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: bernard hogan howe\n",
      "\n",
      "Question: According to official EU population statistics, which is the largest city in the European Union to begin with the letter 'T'?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: turin\n",
      "\n",
      "Question: Whose wife ‚ÄúWouldn‚Äôt have a Willie nor a Sam‚Äù?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: enery eighth\n",
      "\n",
      "Question: Typically related to glass or crystal, the term dichroism refers to two or more what?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: colours colors\n",
      "\n",
      "Question: An insect of the order Diptera is more commonly called a what?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: fly\n",
      "\n",
      "Question: How many countries joined together to create the original European Economic Community following upon the Treaty of Rome in 1957?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: six\n",
      "\n",
      "Question: What William S Burroughs 1961 book popularised the rock music term 'heavy metal', and provided the names for at least two rock bands of the 1970s?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  w\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: soft machine\n",
      "\n",
      "Question: The unrecognized state of Biafra existed from 1967-1970 in the south-east of which country?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  Nigeria\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! üéâ\n",
      "\n",
      "Question: In which city will the 2017 World Athletics Championships take place?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong! The correct answer was: london\n",
      "\n",
      "Question: Which type of seeds are traditionally used in a recipe for seed cake?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Answer:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for playing! You got 1/26 correct!\n"
     ]
    }
   ],
   "source": [
    "#Run the chatbot\n",
    "trivia_chatbot(cleaned_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820d7b2-c8f5-48f2-8984-b3c66bc46772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
